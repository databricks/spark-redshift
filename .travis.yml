language: scala
sudo: false
cache:
  directories:
    - $HOME/.ivy2
# There's no nicer way to specify this matrix; see
# https://github.com/travis-ci/travis-ci/issues/1519.
# Spark 1.5.0 only supports Java 7+.
matrix:
  include:
    # We only test Spark 1.4.1 with Hadooop 2.2.0 because
    # https://github.com/apache/spark/pull/6599 is not present in 1.4.1,
    # so the published Spark Maven artifacts will not work with Hadoop 1.x.
    - jdk: openjdk6
      scala: 2.10.4
      env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.4.1"
    - jdk: openjdk7
      scala: 2.10.4
      env: HADOOP_VERSION="1.0.4" SPARK_VERSION="1.5.0-rc2"
    - jdk: openjdk7
      scala: 2.10.4
      env: HADOOP_VERSION="1.2.1" SPARK_VERSION="1.5.0-rc2"
    - jdk: openjdk7
      scala: 2.10.4
      env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.5.0-rc2"
env:
  global:
    # AWS_REDSHIFT_JDBC_URL
    - secure: "RNkxdKcaKEYuJqxli8naazp42qO5/pgueIzs+J5rHwl39jcBvJMgW3DX8kT7duzdoBb/qrolj/ttbQ3l/30P45+djn0BEwcJMX7G/FGpZYD23yd03qeq7sOKPQl2Ni/OBttYHJMah5rI6aPmAysBZMQO7Wijdenb/RUiU2YcZp0="
    # AWS_REDSHIFT_PASSWORD
    - secure: "g5li3gLejD+/2BIqIm+qHiqBUvCc5l0qnftVaVlLtL7SffErp/twDiFP4gW8eqnFqi2GEC1c9Shf7Z9cOIUunNSBQZdYIVG0f38UfBeDP14nOoIuwZ974O5yggbgZhX0cKvJzINcENGoRNk0FzRwgOdCCiF05IMnRqQxI3C24fE="
    # AWS_REDSHIFT_USER
    - secure: "LIkY/ZpBXK3vSFsdpBSRXEsgfD2wDF52X8OZOlyBJOiZpS4y1/obj8b3VQABDPyPH95bGX/LOpM0vVM137rYgF0pskgVEzLMyZOPpwYqNGPf/d4BtQhBRc8f7+jmr6D4Hrox4jCl0cCKaeiTazun2+Y9E+zgCUDvQ8y9qGctR2k="
    # TEST_AWS_ACCESS_KEY_ID
    - secure: "es6ERiruS8vrv6Ur2GTs5aD3ULcfuGZGJWH/AJhjncVdC5+bkVg2mIMqFjh1sDXlQhUtLXNC9cpg9ZMTBSwn+xYdIr2u8iJZZX3kvmLwKOeR+wsWJpt5WbUPM4eIyZC9tHP9VlL42CJ2AxrHyiGSqSOl1jdMeFMadVUwkmiHg7M="
    # TEST_AWS_SECRET_ACCESS_KEY
    - secure: "RAWTY02D5qKITWoroJFxmB6BUmDXe4NfVHhvNTd5BA3mW55w9yrpJoDLOUk97m6IzX9wQJ+E6M7G1v+BqUD4ZN7s6Clb6B8VQxNVSLc/+T0NN4QPonSivIWBtjFwjoErNN763CTPoNm95YD/qGg61q6gWZrKv+ppfZ0qubldjLw="
    # STS_ROLE_ARN
    - secure: "cuyemI1bqPkWBD5B1FqIKDJb5g/SX5x8lrzkO0J/jkyGY0VLbHxrl5j/9PrKFuvraBK3HC56HEP1Zg+IMvh+uv0D+p5y14C97fAzE33uNgR2aVkamOo92zHvxvXe7zBtqc8rztWsJb1pgkrY7SdgSXgQc88ohey+XecDh4TahTY="
    # AWS_S3_SCRATCH_SPACE
    - secure: "LvndQIW6dHs6nyaMHtblGI/oL+s460lOezFs2BoD0Isenb/O/IM+nY5K9HepTXjJIcq8qvUYnojZX1FCrxxOXX2/+/Iihiq7GzJYdmdMC6hLg9bJYeAFk0dWYT88/AwadrJCBOa3ockRLhiO3dkai7Ki5+M1erfaFiAHHMpJxYQ="

script:
  - sbt -Dhadoop.testVersion=$HADOOP_VERSION -Dspark.testVersion=$SPARK_VERSION coverage test
  - if [ "$TRAVIS_SECURE_ENV_VARS" == "true" ]; then sbt -Dhadoop.version=$HADOOP_VERSION -Dspark.version=$SPARK_VERSION coverage it:test 2> /dev/null; fi
  - sbt scalastyle
  # Disable scalastyle for tests until https://github.com/scalastyle/scalastyle/issues/156 is fixed:
  # - sbt "test:scalastyle"
  - sbt "it:scalastyle"
after_success:
  - bash <(curl -s https://codecov.io/bash)
