language: scala
sudo: false
cache:
  directories:
    - $HOME/.ivy2
# There's no nicer way to specify this matrix; see
# https://github.com/travis-ci/travis-ci/issues/1519.
# Spark 1.5.0 only supports Java 7+.
matrix:
  include:
    # We only test Spark 1.4.1 with Hadooop 2.2.0 because
    # https://github.com/apache/spark/pull/6599 is not present in 1.4.1,
    # so the published Spark Maven artifacts will not work with Hadoop 1.x.
    - jdk: openjdk6
      scala: 2.10.5
      env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.4.1" SPARK_AVRO_VERSION="2.0.1"
    - jdk: openjdk7
      scala: 2.10.5
      env: HADOOP_VERSION="1.0.4" SPARK_VERSION="1.5.0" SPARK_AVRO_VERSION="2.0.1"
    - jdk: openjdk7
      scala: 2.10.5
      env: HADOOP_VERSION="1.2.1" SPARK_VERSION="1.5.0" SPARK_AVRO_VERSION="2.0.1"
    - jdk: openjdk7
      scala: 2.10.5
      env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.5.0" SPARK_AVRO_VERSION="2.0.1"
    # Tests against Spark 1.6.0-SNAPHSOT, to be updated once 1.6.0 is released:
    - jdk: openjdk7
      scala: 2.10.5
      env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.6.0-SNAPSHOT" SPARK_AVRO_VERSION="2.0.1"
    # Configuration corresponding to DBC 1.4.x driver package as of DBC 2.4,
    # which uses spark-avro 1.0.0. We use Hadoop 2.2.0 here, while DBC uses
    # 1.2.1, because the 1.4.1 published to Maven Central is a Hadoop 2.x build.
    - jdk: openjdk7
      scala: 2.10.5
      env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.4.1" SPARK_AVRO_VERSION="1.0.0"
    # Scala 2.11 tests:
    - jdk: openjdk7
      scala: 2.11.7
      env: HADOOP_VERSION="2.2.0" SPARK_VERSION="1.5.0" SPARK_AVRO_VERSION="2.0.1"
env:
  global:
    # AWS_REDSHIFT_JDBC_URL
    - secure: "RNkxdKcaKEYuJqxli8naazp42qO5/pgueIzs+J5rHwl39jcBvJMgW3DX8kT7duzdoBb/qrolj/ttbQ3l/30P45+djn0BEwcJMX7G/FGpZYD23yd03qeq7sOKPQl2Ni/OBttYHJMah5rI6aPmAysBZMQO7Wijdenb/RUiU2YcZp0="
    # AWS_REDSHIFT_PASSWORD
    - secure: "g5li3gLejD+/2BIqIm+qHiqBUvCc5l0qnftVaVlLtL7SffErp/twDiFP4gW8eqnFqi2GEC1c9Shf7Z9cOIUunNSBQZdYIVG0f38UfBeDP14nOoIuwZ974O5yggbgZhX0cKvJzINcENGoRNk0FzRwgOdCCiF05IMnRqQxI3C24fE="
    # AWS_REDSHIFT_USER
    - secure: "LIkY/ZpBXK3vSFsdpBSRXEsgfD2wDF52X8OZOlyBJOiZpS4y1/obj8b3VQABDPyPH95bGX/LOpM0vVM137rYgF0pskgVEzLMyZOPpwYqNGPf/d4BtQhBRc8f7+jmr6D4Hrox4jCl0cCKaeiTazun2+Y9E+zgCUDvQ8y9qGctR2k="
    # TEST_AWS_ACCESS_KEY_ID
    - secure: "bsB6YwkscUxtzcZOKja4Y69IR3JqvCP3W/4vFftW/v33/hOC3EBz7TVNKS+ZIomBUQYJnzsMfM59bj7YEc3KZe8WxIcUdLI40hg0X5O1RhJDNPW+0oGbWshmzyua+hY1y7nRja+8/17tYTbAi1+MhscRu+O/2aWaXolA9BicuX0="
    # TEST_AWS_SECRET_ACCESS_KEY
    - secure: "cGxnZh4be9XiPBOMxe9wHYwEfrWNw4zSjmvGFEC9UUV11ydHLo5wrXtcTVFmY7qxUxYeb0NB2N+CQXE0GcyUKoTviKG9sOS3cxR1q30FsdOVcWDKAzpBUmzDTMwDLAUMysziyOtMorDlNVydqYdYLMpiUN0O+eDKA+iOHlJp7fo="
    # STS_ROLE_ARN
    - secure: "cuyemI1bqPkWBD5B1FqIKDJb5g/SX5x8lrzkO0J/jkyGY0VLbHxrl5j/9PrKFuvraBK3HC56HEP1Zg+IMvh+uv0D+p5y14C97fAzE33uNgR2aVkamOo92zHvxvXe7zBtqc8rztWsJb1pgkrY7SdgSXgQc88ohey+XecDh4TahTY="
    # AWS_S3_SCRATCH_SPACE
    - secure: "LvndQIW6dHs6nyaMHtblGI/oL+s460lOezFs2BoD0Isenb/O/IM+nY5K9HepTXjJIcq8qvUYnojZX1FCrxxOXX2/+/Iihiq7GzJYdmdMC6hLg9bJYeAFk0dWYT88/AwadrJCBOa3ockRLhiO3dkai7Ki5+M1erfaFiAHHMpJxYQ="

script:
  - ./dev/run-tests-travis.sh
after_success:
  - bash <(curl -s https://codecov.io/bash)
